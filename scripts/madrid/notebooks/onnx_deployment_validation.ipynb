{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.path.abspath('../'), 'predictions_collapsed'))\n",
    "sys.path.append(os.path.join(os.path.abspath('../'), 'src'))\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import cm\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "import glob\n",
    "import datetime\n",
    "from config_loader import (\n",
    "    D_CONFIG, DATASET_TOP_PATH,\n",
    "    DATASET_SITE_PATH, PROJECT_REPO_DIR, PROJECT_CONDA_ENV_YAML,\n",
    "    DATASET_COLLAPSED_FEAT_DYNAMIC_INPUT_OUTPUT_PATH,\n",
    "    RESULTS_COLLAPSED_FEAT_DYNAMIC_INPUT_OUTPUT_PATH\n",
    "    )\n",
    "\n",
    "sys.path.append(os.path.join(PROJECT_REPO_DIR, 'src'))\n",
    "from feature_transformation import *\n",
    "from utils import load_data_dict_json\n",
    "deployment_code_dir = os.path.join('/home', 'prash', 'clinical_deterioration')\n",
    "sys.path.append(deployment_code_dir)\n",
    "sys.path.append(os.path.join(deployment_code_dir, 'src_code'))\n",
    "sys.path.append(os.path.join(deployment_code_dir, 'data_example'))\n",
    "sys.path.append(os.path.join(deployment_code_dir, 'src_code', 'utils_specs'))\n",
    "\n",
    "\n",
    "RESULTS_COLLAPSED_FEAT_DYNAMIC_INPUT_OUTPUT_PATH = os.path.join(RESULTS_COLLAPSED_FEAT_DYNAMIC_INPUT_OUTPUT_PATH, 'sklearn_logistic_regression')\n",
    "CLF_TRAIN_TEST_SPLIT_PATH=os.path.join(DATASET_COLLAPSED_FEAT_DYNAMIC_INPUT_OUTPUT_PATH, 'classifier_train_test_split')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the raw data as well as featurized data for a test participant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_df = pd.read_csv(os.path.join(CLF_TRAIN_TEST_SPLIT_PATH, 'x_test.csv.gz'), nrows=1000)\n",
    "y_test_df = pd.read_csv(os.path.join(CLF_TRAIN_TEST_SPLIT_PATH, 'y_test.csv.gz'), nrows=1000)\n",
    "\n",
    "test_adm_id = 11801416\n",
    "x_test_df = x_test_df[x_test_df.hospital_admission_id==test_adm_id].reset_index(drop=True)\n",
    "y_test_df = y_test_df[y_test_df.hospital_admission_id==test_adm_id].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vitals_df = pd.read_csv(os.path.join(DATASET_SITE_PATH, 'vitals_before_icu.csv.gz'))\n",
    "labs_df = pd.read_csv(os.path.join(DATASET_SITE_PATH, 'labs_before_icu.csv.gz'))\n",
    "medications_df = pd.read_csv(os.path.join(DATASET_SITE_PATH, 'medications_before_icu.csv.gz'))\n",
    "demographics_df = pd.read_csv(os.path.join(DATASET_SITE_PATH, 'demographics_before_icu.csv.gz'))\n",
    "\n",
    "demographics_dd = load_data_dict_json(os.path.join(DATASET_SITE_PATH,\n",
    "                                                  'Spec-Demographics.json'))\n",
    "vitals_dd = load_data_dict_json(os.path.join(DATASET_SITE_PATH,\n",
    "                                                  'Spec-Vitals.json'))\n",
    "labs_dd = load_data_dict_json(os.path.join(DATASET_SITE_PATH,\n",
    "                                                  'Spec-Labs.json'))\n",
    "medications_dd = load_data_dict_json(os.path.join(DATASET_SITE_PATH,\n",
    "                                                  'Spec-Medications.json'))\n",
    "\n",
    "collapsed_features_dd = load_data_dict_json(os.path.join(CLF_TRAIN_TEST_SPLIT_PATH, 'Spec_features.json'))\n",
    "collapsed_features = parse_feature_cols(collapsed_features_dd)\n",
    "\n",
    "vitals_df = vitals_df[vitals_df.hospital_admission_id==test_adm_id].reset_index(drop=True)\n",
    "labs_df = labs_df[labs_df.hospital_admission_id==test_adm_id].reset_index(drop=True)\n",
    "medications_df = medications_df[medications_df.hospital_admission_id==test_adm_id].reset_index(drop=True)\n",
    "demographics_df = demographics_df[demographics_df.hospital_admission_id==test_adm_id].reset_index(drop=True)\n",
    "\n",
    "\n",
    "vital_cols = parse_feature_cols(vitals_dd)\n",
    "lab_cols = parse_feature_cols(labs_dd)\n",
    "medication_cols = parse_feature_cols(medications_dd)\n",
    "demographic_cols = parse_feature_cols(demographics_dd)\n",
    "id_cols = parse_id_cols(vitals_dd)\n",
    "time_col = parse_time_cols(vitals_dd)[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an artificial json for this participant that can be inserted into deployment code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_pid = vitals_df.patient_id.unique()[0]\n",
    "curr_adm_ts = demographics_df.admission_timestamp.unique()[0]\n",
    "curr_pred_start_ts = curr_adm_ts\n",
    "\n",
    "prediction_window_end_hrs = 24\n",
    "curr_pred_ts = str(pd.to_datetime(curr_adm_ts) + datetime.timedelta(hours=prediction_window_end_hrs))\n",
    "\n",
    "api_dict = dict()\n",
    "\n",
    "api_dict['patient_id'] = int(curr_pid)\n",
    "api_dict['start_datetime'] = curr_adm_ts\n",
    "api_dict['prediction_datetime'] = curr_pred_ts\n",
    "api_dict['measurements_over_time_by_variable'] = dict()\n",
    "\n",
    "for feature_cols, features_df, features_dd in [(vital_cols, vitals_df, vitals_dd),\n",
    "                                               (lab_cols, labs_df, labs_dd), \n",
    "                                               (medication_cols, medications_df, medications_dd),\n",
    "                                               (demographic_cols, demographics_df, demographics_dd)]:\n",
    "\n",
    "    for col in feature_cols:\n",
    "        curr_feature= features_df[col].values\n",
    "        mask = np.logical_not(np.isnan(curr_feature))\n",
    "        curr_feature = curr_feature[mask]\n",
    "        if time_col in features_df.columns:\n",
    "            curr_t = features_df[time_col].values[mask]\n",
    "\n",
    "            # keep only measurements before the prediction time\n",
    "            keep_t = curr_t <= prediction_window_end_hrs\n",
    "            curr_t = curr_t[keep_t]\n",
    "            curr_feature = curr_feature[keep_t]\n",
    "\n",
    "            if len(curr_t)>0:\n",
    "                api_dict['measurements_over_time_by_variable'][col] = []\n",
    "                for ii in range(len(curr_t)):\n",
    "                    curr_t_feature_dict = dict()\n",
    "                    curr_t_feature_dict['value'] = float(curr_feature[ii])\n",
    "                    curr_t_feature_dict['datetime'] = str(pd.to_datetime(api_dict['start_datetime']) + datetime.timedelta(hours=curr_t[ii]))\n",
    "                    curr_t_feature_dict['code'] = [d for d in features_dd['schema']['fields'] if d['name']==col][0]['codes']\n",
    "                    api_dict['measurements_over_time_by_variable'][col].append(curr_t_feature_dict)\n",
    "        else:\n",
    "            api_dict['measurements_over_time_by_variable'][col] = []\n",
    "            curr_static_feature_dict = dict()\n",
    "            curr_static_feature_dict['value'] = float(curr_feature)\n",
    "            curr_static_feature_dict['datetime'] = str(pd.to_datetime(api_dict['start_datetime']))\n",
    "            curr_static_feature_dict['code'] = [d for d in features_dd['schema']['fields'] if d['name']==col][0]['codes']\n",
    "            api_dict['measurements_over_time_by_variable'][col].append(curr_static_feature_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Make sure to save json in file untracked by git\n",
    "with open(os.path.json('\\home\\prash\\datasets','real_mock_1.json'), 'w') as fp:\n",
    "    json.dump(api_dict, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Featurize and predict with the artificial jsons using the exact code as in deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```console\n",
    "python run_deploy_demo.py --input_data_ts_json_fpath data_example/real_mock_1.json --pretrained_model_path data_example/lightGBM_min_samples_per_leaf\\=1024-max_leaves\\=128-n_estimators\\=100-frac_features_for_clf\\=0.33-frac_training_samples_per_tree\\=0.33.onnx --pretrained_watermark_path data_example/watermark.LR.onnx1.6.0_py3.8.8_darwin.txt\n",
    "-------------------------------\n",
    "Environment compatibility check\n",
    "-------------------------------\n",
    "      package  train_version    cur_version\n",
    " Architecture          64bit          64bit\n",
    "      Machine         x86_64         x86_64\n",
    "           OS         Darwin          Linux\n",
    "       Python          3.8.8          3.8.2\n",
    "        numpy         1.20.1         1.19.4\n",
    "         onnx          1.6.0         1.10.1\n",
    "  onnxruntime  not installed          1.8.1\n",
    "     protobuf  not installed  not installed\n",
    " scikit-learn         0.24.1         0.22.1\n",
    "        scipy          1.6.2          1.4.1\n",
    "     skl2onnx          1.9.2          1.9.2\n",
    "\n",
    "------------------------\n",
    "Loading pretrained model\n",
    "------------------------\n",
    "Attempting load from file:\n",
    "/home/prash/clinical_deterioration/data_example/lightGBM_min_samples_per_leaf=1024-max_leaves=128-n_estimators=100-frac_features_for_clf=0.33-frac_training_samples_per_tree=0.33.onnx\n",
    "... done. Load complete.\n",
    "\n",
    "-----------------------\n",
    "Loading input data\n",
    "-----------------------\n",
    "For Patient #1539160 from 2022-08-23 01:44:00 - 2022-08-24 01:44:00\n",
    "   3 obs. of body_temperature\n",
    "   4 obs. of diastolic_blood_pressure\n",
    "   4 obs. of heart_rate\n",
    "   4 obs. of o2_sat\n",
    "   4 obs. of systolic_blood_pressure\n",
    "   1 obs. of basophils\n",
    "   1 obs. of bicarbonate_venous_blood\n",
    "   1 obs. of creatinine_in_serum\n",
    "   1 obs. of eosinophils\n",
    "   1 obs. of erithrocytes\n",
    "   1 obs. of glucose_in_serum\n",
    "   1 obs. of hemoglobin\n",
    "   1 obs. of lymphocytes\n",
    "   1 obs. of monocytes\n",
    "   1 obs. of neutrophils\n",
    "   1 obs. of oxygen_venous_blood\n",
    "   1 obs. of ph_venous_blood\n",
    "   1 obs. of potassium_in_serum\n",
    "   1 obs. of sodium_in_serum\n",
    "   1 obs. of age_at_admission\n",
    "   1 obs. of gender_is_male\n",
    "   1 obs. of gender_is_unknown\n",
    "\n",
    "-----------------------\n",
    "Predicting outcome output_probability\n",
    "-----------------------\n",
    "\n",
    "Asking for a probability of deterioration, we get:\n",
    "0.1957433\n",
    "\n",
    "Asking for a binary decision, we get:\n",
    "0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare predicted probas of deployment code v/s test set predicted probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{0: 0.8042566776275635, 1: 0.19574332237243652}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load model \n",
    "onx_file = '/home/prash/clinical_deterioration/data_example/lightGBM_min_samples_per_leaf=1024-max_leaves=128-n_estimators=100-frac_features_for_clf=0.33-frac_training_samples_per_tree=0.33.onnx'\n",
    "\n",
    "# load collapsed_features\n",
    "x_test = x_test_df[x_test_df.stop==24.0][collapsed_features].values\n",
    "\n",
    "sess = rt.InferenceSession(onx_file)\n",
    "input_name = sess.get_inputs()[0].name\n",
    "proba_label_name = sess.get_outputs()[1].name\n",
    "pred_probas_onx = sess.run([proba_label_name], {input_name: x_test.astype(np.float32)})[0]\n",
    "\n",
    "\n",
    "pred_probas_onx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
