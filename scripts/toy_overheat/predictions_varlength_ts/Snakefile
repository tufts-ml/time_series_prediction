'''
Produce a pertstep feature representation on this toy dataset

Usage
-----
Split 1-D features into train and test
>> snakemake --cores 1 split_1d_features_into_train_and_test

Split 2-D features into train and test
>> snakemake --cores 1 split_2d_features_into_train_and_test
>> snakemake --cores 1 split_2d_features_into_many_train_and_test


Split features with transient overheat into train and test
>> snakemake --cores 1 split_transient_overheat_features_into_train_and_test

Split features with global overheat into train and test
>> snakemake --cores 1 split_global_overheat_features_into_train_and_test
'''

# Default environment variables
# Can override with local env variables

TOY_OVERHEAT_VERSION = os.environ.get('TOY_OVERHEAT_VERSION', 'v20200515')
PROJECT_REPO_DIR = os.environ.get("PROJECT_REPO_DIR", os.path.abspath("../../../"))
PROJECT_CONDA_ENV_YAML = os.path.join(PROJECT_REPO_DIR, "ts_pred.yml")

DATASET_STD_PATH = os.path.join(PROJECT_REPO_DIR, 'datasets', 'toy_overheat', TOY_OVERHEAT_VERSION)
DATASET_SPLIT_PATH = os.path.join(PROJECT_REPO_DIR, 'datasets', 'toy_overheat', TOY_OVERHEAT_VERSION, 'train_test_split_dir')
DATASET_RNN_SPLIT_PATH = os.path.join(DATASET_STD_PATH, 'rnn_data', 'train_test_split_dir')
DATASET_CNN_SPLIT_PATH = os.path.join(DATASET_STD_PATH, 'cnn_data', 'train_test_split_dir')
configfile:"pchmm_train_test_splitting.json"

rule all:
    input:
        x_train_csv=os.path.join(DATASET_SPLIT_PATH, 'x_train.csv'),
        x_test_csv=os.path.join(DATASET_SPLIT_PATH, 'x_test.csv'),
        y_train_csv=os.path.join(DATASET_SPLIT_PATH, 'y_train.csv'),
        y_test_csv=os.path.join(DATASET_SPLIT_PATH, 'y_test.csv')

rule split_1d_features_into_train_and_test:
    input:
        script=os.path.join(PROJECT_REPO_DIR, 'src', 'split_dataset.py'),
        x_csv=os.path.join(DATASET_STD_PATH, 'features_per_tstep.csv'),
        x_json=os.path.join(DATASET_STD_PATH, 'Spec_FeaturesPerTimestep.json'),
        y_csv=os.path.join(DATASET_STD_PATH, 'outcomes_per_seq.csv'),
        y_json=os.path.join(DATASET_STD_PATH, 'Spec_OutcomesPerSequence.json')

    output:
        x_train_csv=os.path.join(DATASET_SPLIT_PATH, 'x_train.csv'),
        x_test_csv=os.path.join(DATASET_SPLIT_PATH, 'x_test.csv'),
        y_train_csv=os.path.join(DATASET_SPLIT_PATH, 'y_train.csv'),
        y_test_csv=os.path.join(DATASET_SPLIT_PATH, 'y_test.csv')

    conda:
        PROJECT_CONDA_ENV_YAML

    shell:
        '''
        mkdir -p DATASET_SPLIT_PATH \
        && python -u {input.script} \
            --input {input.x_csv} \
            --data_dict {input.x_json} \
            --test_size 0.1 \
            --group_cols sequence_id \
            --train_csv_filename {output.x_train_csv} \
            --test_csv_filename {output.x_test_csv} \
        && python -u {input.script} \
            --input {input.y_csv} \
            --data_dict {input.y_json} \
            --test_size 0.1 \
            --group_cols sequence_id \
            --train_csv_filename {output.y_train_csv} \
            --test_csv_filename {output.y_test_csv}
        '''.replace("DATASET_SPLIT_PATH", DATASET_SPLIT_PATH)


rule split_2d_features_into_many_train_and_test:
    input:
        [os.path.join(DATASET_SPLIT_PATH, 'x_train_{missing_handling}_observed={perc_obs}_perc.csv').format(perc_obs=perc_obs, missing_handling=missing_handling) for missing_handling in config['missing_handling'] for perc_obs in config['perc_obs']]

rule split_2d_features_into_train_and_test:
    input:
        script=os.path.join(PROJECT_REPO_DIR, 'src', 'split_dataset.py'),
        x_csv=os.path.join(DATASET_STD_PATH, 'features_2d_per_tstep_{missing_handling}_observed={perc_obs}_perc.csv'),
        x_json=os.path.join(DATASET_STD_PATH, 'Spec_Features2DPerTimestep.json'),
        y_csv=os.path.join(DATASET_STD_PATH, 'outcomes_per_seq.csv'),
        y_json=os.path.join(DATASET_STD_PATH, 'Spec_OutcomesPerSequence.json')

    output:
        x_train_csv=os.path.join(DATASET_SPLIT_PATH, 'x_train_{missing_handling}_observed={perc_obs}_perc.csv'),
        x_test_csv=os.path.join(DATASET_SPLIT_PATH, 'x_test_{missing_handling}_observed={perc_obs}_perc.csv'),
        x_valid_csv=os.path.join(DATASET_SPLIT_PATH, 'x_valid_{missing_handling}_observed={perc_obs}_perc.csv'),
        y_train_csv=os.path.join(DATASET_SPLIT_PATH, 'y_train_{missing_handling}_observed={perc_obs}_perc.csv'),
        y_valid_csv=os.path.join(DATASET_SPLIT_PATH, 'y_valid_{missing_handling}_observed={perc_obs}_perc.csv'),
        y_test_csv=os.path.join(DATASET_SPLIT_PATH, 'y_test_{missing_handling}_observed={perc_obs}_perc.csv'),
        x_json=os.path.join(DATASET_SPLIT_PATH, 'x_dict_{missing_handling}_observed={perc_obs}_perc.json'),
        y_json=os.path.join(DATASET_SPLIT_PATH, 'y_dict_{missing_handling}_observed={perc_obs}_perc.json')

    conda:
        PROJECT_CONDA_ENV_YAML

    shell:
        '''
        mkdir -p DATASET_SPLIT_PATH \
        && python -u {input.script} \
            --input {input.x_csv} \
            --data_dict {input.x_json} \
            --test_size 0.15 \
            --group_cols sequence_id \
            --train_csv_filename {output.x_train_csv} \
            --valid_csv_filename {output.x_valid_csv} \
            --test_csv_filename {output.x_test_csv} \
            --output_data_dict_filename {output.x_json} \
        && python -u {input.script} \
            --input {input.y_csv} \
            --data_dict {input.y_json} \
            --test_size 0.15 \
            --group_cols sequence_id \
            --train_csv_filename {output.y_train_csv} \
            --valid_csv_filename {output.y_valid_csv} \
            --test_csv_filename {output.y_test_csv} \
            --output_data_dict_filename {output.y_json} \
        '''.replace("DATASET_SPLIT_PATH", DATASET_SPLIT_PATH)


rule split_global_overheat_features_into_train_and_test:
    input:
        script=os.path.join(PROJECT_REPO_DIR, 'src', 'split_dataset.py'),
        x_csv=os.path.join(DATASET_STD_PATH, 'rnn_features_per_tstep.csv'),
        x_json=os.path.join(DATASET_STD_PATH, 'Spec_FeaturesPerTimestep.json'),
        y_csv=os.path.join(DATASET_STD_PATH, 'rnn_outcomes_per_seq.csv'),
        y_json=os.path.join(DATASET_STD_PATH, 'Spec_OutcomesPerSequence.json')

    output:
        x_train_csv=os.path.join(DATASET_RNN_SPLIT_PATH, 'x_train.csv'),
        x_test_csv=os.path.join(DATASET_RNN_SPLIT_PATH, 'x_test.csv'),
        y_train_csv=os.path.join(DATASET_RNN_SPLIT_PATH, 'y_train.csv'),
        y_test_csv=os.path.join(DATASET_RNN_SPLIT_PATH, 'y_test.csv'),
        x_json=os.path.join(DATASET_RNN_SPLIT_PATH, 'x_dict.json'),
        y_json=os.path.join(DATASET_RNN_SPLIT_PATH, 'y_dict.json')

    conda:
        PROJECT_CONDA_ENV_YAML

    shell:
        '''
        mkdir -p DATASET_RNN_SPLIT_PATH \
        && python -u {input.script} \
            --input {input.x_csv} \
            --data_dict {input.x_json} \
            --test_size 0.1 \
            --group_cols sequence_id \
            --train_csv_filename {output.x_train_csv} \
            --test_csv_filename {output.x_test_csv} \
            --output_data_dict_filename {output.x_json} \
        && python -u {input.script} \
            --input {input.y_csv} \
            --data_dict {input.y_json} \
            --test_size 0.1 \
            --group_cols sequence_id \
            --train_csv_filename {output.y_train_csv} \
            --test_csv_filename {output.y_test_csv} \
            --output_data_dict_filename {output.y_json} \
        '''.replace("DATASET_RNN_SPLIT_PATH", DATASET_RNN_SPLIT_PATH)
        

rule split_transient_overheat_features_into_train_and_test:
    input:
        script=os.path.join(PROJECT_REPO_DIR, 'src', 'split_dataset.py'),
        x_csv=os.path.join(DATASET_STD_PATH, 'cnn_features_per_tstep.csv'),
        x_json=os.path.join(DATASET_STD_PATH, 'Spec_FeaturesPerTimestep.json'),
        y_csv=os.path.join(DATASET_STD_PATH, 'cnn_outcomes_per_seq.csv'),
        y_json=os.path.join(DATASET_STD_PATH, 'Spec_OutcomesPerSequence.json')

    output:
        x_train_csv=os.path.join(DATASET_CNN_SPLIT_PATH, 'x_train.csv'),
        x_test_csv=os.path.join(DATASET_CNN_SPLIT_PATH, 'x_test.csv'),
        y_train_csv=os.path.join(DATASET_CNN_SPLIT_PATH, 'y_train.csv'),
        y_test_csv=os.path.join(DATASET_CNN_SPLIT_PATH, 'y_test.csv'),
        x_json=os.path.join(DATASET_CNN_SPLIT_PATH, 'x_dict.json'),
        y_json=os.path.join(DATASET_CNN_SPLIT_PATH, 'y_dict.json')

    conda:
        PROJECT_CONDA_ENV_YAML

    shell:
        '''
        mkdir -p DATASET_CNN_SPLIT_PATH \
        && python -u {input.script} \
            --input {input.x_csv} \
            --data_dict {input.x_json} \
            --test_size 0.1 \
            --group_cols sequence_id \
            --train_csv_filename {output.x_train_csv} \
            --test_csv_filename {output.x_test_csv} \
            --output_data_dict_filename {output.x_json} \
        && python -u {input.script} \
            --input {input.y_csv} \
            --data_dict {input.y_json} \
            --test_size 0.1 \
            --group_cols sequence_id \
            --train_csv_filename {output.y_train_csv} \
            --test_csv_filename {output.y_test_csv} \
            --output_data_dict_filename {output.y_json} \
        '''.replace("DATASET_CNN_SPLIT_PATH", DATASET_CNN_SPLIT_PATH)
