{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# sys.path.append('./GRU-D/')\n",
    "# from models import create_grud_model\n",
    "# import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "PROJECT_SRC_DIR = '/cluster/tufts/hugheslab/prath01/projects/time_series_prediction/src/'\n",
    "sys.path.append(PROJECT_SRC_DIR)\n",
    "sys.path.append(os.path.join(PROJECT_SRC_DIR, \"rnn\"))\n",
    "sys.path.append(os.path.abspath(\"../src\"))\n",
    "from dataset_loader import TidySequentialDataCSVLoader\n",
    "from feature_transformation import parse_id_cols, parse_output_cols, parse_feature_cols, parse_id_cols, parse_time_cols\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load MIMIC data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_dir = '/cluster/tufts/hugheslab/prath01/projects/time_series_prediction/datasets/mimic3_inhospital_mortality/v20201207/split-by=subject_id/features_per_timeslice/classifier_train_test_split_dir/'\n",
    "x_dict_file = '/cluster/tufts/hugheslab/prath01/projects/time_series_prediction/datasets/mimic3_inhospital_mortality/v20201207/split-by=subject_id/features_per_timeslice/classifier_train_test_split_dir/x_dict.json'\n",
    "y_dict_file = '/cluster/tufts/hugheslab/prath01/projects/time_series_prediction/datasets/mimic3_inhospital_mortality/v20201207/split-by=subject_id/features_per_timeslice/classifier_train_test_split_dir/y_dict.json'\n",
    "\n",
    "x_train_csv_filename = os.path.join(train_test_dir, 'x_train_first_24_hours.csv')\n",
    "y_train_csv_filename = os.path.join(train_test_dir, 'y_train_first_24_hours.csv')\n",
    "# x_train_df = pd.read_csv(x_train_csv_filename)\n",
    "# y_train_df = pd.read_csv(y_train_csv_filename)\n",
    "\n",
    "x_valid_csv_filename = os.path.join(train_test_dir, 'x_valid_first_24_hours.csv')\n",
    "y_valid_csv_filename = os.path.join(train_test_dir, 'y_valid_first_24_hours.csv')\n",
    "# x_valid_df = pd.read_csv(x_valid_csv_filename)\n",
    "# y_valid_df = pd.read_csv(y_valid_csv_filename)\n",
    "\n",
    "x_test_csv_filename = os.path.join(train_test_dir, 'x_test_first_24_hours.csv')\n",
    "y_test_csv_filename = os.path.join(train_test_dir, 'y_test_first_24_hours.csv')\n",
    "# x_test_df = pd.read_csv(x_test_csv_filename)\n",
    "# y_test_df = pd.read_csv(y_test_csv_filename)\n",
    "\n",
    "\n",
    "train_x = pd.read_csv(x_train_csv_filename)\n",
    "valid_x = pd.read_csv(x_valid_csv_filename)\n",
    "test_x = pd.read_csv(x_test_csv_filename)\n",
    "train_y = pd.read_csv(y_train_csv_filename)\n",
    "valid_y = pd.read_csv(y_valid_csv_filename)\n",
    "test_y = pd.read_csv(y_test_csv_filename)\n",
    "\n",
    "x_data_dict = json.load(open(x_dict_file))\n",
    "y_data_dict = json.load(open(y_dict_file))\n",
    "\n",
    "feature_cols = parse_feature_cols(x_data_dict['schema'])\n",
    "id_cols = parse_id_cols(x_data_dict['schema'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>icustay_id</th>\n",
       "      <th>hours_in</th>\n",
       "      <th>age</th>\n",
       "      <th>alanine aminotransferase</th>\n",
       "      <th>albumin</th>\n",
       "      <th>albumin ascites</th>\n",
       "      <th>albumin pleural</th>\n",
       "      <th>albumin urine</th>\n",
       "      <th>alkaline phosphate</th>\n",
       "      <th>anion gap</th>\n",
       "      <th>asparate aminotransferase</th>\n",
       "      <th>basophils</th>\n",
       "      <th>bicarbonate</th>\n",
       "      <th>bilirubin</th>\n",
       "      <th>blood urea nitrogen</th>\n",
       "      <th>calcium</th>\n",
       "      <th>calcium ionized</th>\n",
       "      <th>calcium urine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>145834</td>\n",
       "      <td>211552</td>\n",
       "      <td>0</td>\n",
       "      <td>76.526794</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73.0</td>\n",
       "      <td>20.666666</td>\n",
       "      <td>69.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.333334</td>\n",
       "      <td>0.8</td>\n",
       "      <td>44.2</td>\n",
       "      <td>6.92</td>\n",
       "      <td>0.963333</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145834</td>\n",
       "      <td>211552</td>\n",
       "      <td>1</td>\n",
       "      <td>76.526794</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>145834</td>\n",
       "      <td>211552</td>\n",
       "      <td>2</td>\n",
       "      <td>76.526794</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.060000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>145834</td>\n",
       "      <td>211552</td>\n",
       "      <td>3</td>\n",
       "      <td>76.526794</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>145834</td>\n",
       "      <td>211552</td>\n",
       "      <td>4</td>\n",
       "      <td>76.526794</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>145834</td>\n",
       "      <td>211552</td>\n",
       "      <td>5</td>\n",
       "      <td>76.526794</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>145834</td>\n",
       "      <td>211552</td>\n",
       "      <td>6</td>\n",
       "      <td>76.526794</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.030000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>145834</td>\n",
       "      <td>211552</td>\n",
       "      <td>7</td>\n",
       "      <td>76.526794</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.0</td>\n",
       "      <td>6.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>145834</td>\n",
       "      <td>211552</td>\n",
       "      <td>8</td>\n",
       "      <td>76.526794</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>145834</td>\n",
       "      <td>211552</td>\n",
       "      <td>9</td>\n",
       "      <td>76.526794</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>145834</td>\n",
       "      <td>211552</td>\n",
       "      <td>10</td>\n",
       "      <td>76.526794</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>145834</td>\n",
       "      <td>211552</td>\n",
       "      <td>11</td>\n",
       "      <td>76.526794</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>145834</td>\n",
       "      <td>211552</td>\n",
       "      <td>12</td>\n",
       "      <td>76.526794</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>145834</td>\n",
       "      <td>211552</td>\n",
       "      <td>13</td>\n",
       "      <td>76.526794</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.110000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>145834</td>\n",
       "      <td>211552</td>\n",
       "      <td>14</td>\n",
       "      <td>76.526794</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>145834</td>\n",
       "      <td>211552</td>\n",
       "      <td>15</td>\n",
       "      <td>76.526794</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>145834</td>\n",
       "      <td>211552</td>\n",
       "      <td>16</td>\n",
       "      <td>76.526794</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>145834</td>\n",
       "      <td>211552</td>\n",
       "      <td>17</td>\n",
       "      <td>76.526794</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>145834</td>\n",
       "      <td>211552</td>\n",
       "      <td>18</td>\n",
       "      <td>76.526794</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>145834</td>\n",
       "      <td>211552</td>\n",
       "      <td>19</td>\n",
       "      <td>76.526794</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>145834</td>\n",
       "      <td>211552</td>\n",
       "      <td>20</td>\n",
       "      <td>76.526794</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.130000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>145834</td>\n",
       "      <td>211552</td>\n",
       "      <td>21</td>\n",
       "      <td>76.526794</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>145834</td>\n",
       "      <td>211552</td>\n",
       "      <td>22</td>\n",
       "      <td>76.526794</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>145834</td>\n",
       "      <td>211552</td>\n",
       "      <td>23</td>\n",
       "      <td>76.526794</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>145834</td>\n",
       "      <td>211552</td>\n",
       "      <td>24</td>\n",
       "      <td>76.526794</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>185777</td>\n",
       "      <td>294638</td>\n",
       "      <td>0</td>\n",
       "      <td>47.845047</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    subject_id  hadm_id  icustay_id  hours_in        age  \\\n",
       "0            3   145834      211552         0  76.526794   \n",
       "1            3   145834      211552         1  76.526794   \n",
       "2            3   145834      211552         2  76.526794   \n",
       "3            3   145834      211552         3  76.526794   \n",
       "4            3   145834      211552         4  76.526794   \n",
       "5            3   145834      211552         5  76.526794   \n",
       "6            3   145834      211552         6  76.526794   \n",
       "7            3   145834      211552         7  76.526794   \n",
       "8            3   145834      211552         8  76.526794   \n",
       "9            3   145834      211552         9  76.526794   \n",
       "10           3   145834      211552        10  76.526794   \n",
       "11           3   145834      211552        11  76.526794   \n",
       "12           3   145834      211552        12  76.526794   \n",
       "13           3   145834      211552        13  76.526794   \n",
       "14           3   145834      211552        14  76.526794   \n",
       "15           3   145834      211552        15  76.526794   \n",
       "16           3   145834      211552        16  76.526794   \n",
       "17           3   145834      211552        17  76.526794   \n",
       "18           3   145834      211552        18  76.526794   \n",
       "19           3   145834      211552        19  76.526794   \n",
       "20           3   145834      211552        20  76.526794   \n",
       "21           3   145834      211552        21  76.526794   \n",
       "22           3   145834      211552        22  76.526794   \n",
       "23           3   145834      211552        23  76.526794   \n",
       "24           3   145834      211552        24  76.526794   \n",
       "25           4   185777      294638         0  47.845047   \n",
       "\n",
       "    alanine aminotransferase  albumin  albumin ascites  albumin pleural  \\\n",
       "0                       25.0      1.8              NaN              NaN   \n",
       "1                        NaN      NaN              NaN              NaN   \n",
       "2                        NaN      NaN              NaN              NaN   \n",
       "3                        NaN      NaN              NaN              NaN   \n",
       "4                        NaN      NaN              NaN              NaN   \n",
       "5                        NaN      NaN              NaN              NaN   \n",
       "6                        NaN      NaN              NaN              NaN   \n",
       "7                        NaN      NaN              NaN              NaN   \n",
       "8                        NaN      NaN              NaN              NaN   \n",
       "9                        NaN      NaN              NaN              NaN   \n",
       "10                       NaN      NaN              NaN              NaN   \n",
       "11                       NaN      NaN              NaN              NaN   \n",
       "12                       NaN      NaN              NaN              NaN   \n",
       "13                       NaN      NaN              NaN              NaN   \n",
       "14                       NaN      NaN              NaN              NaN   \n",
       "15                       NaN      NaN              NaN              NaN   \n",
       "16                       NaN      NaN              NaN              NaN   \n",
       "17                       NaN      NaN              NaN              NaN   \n",
       "18                       NaN      NaN              NaN              NaN   \n",
       "19                       NaN      NaN              NaN              NaN   \n",
       "20                       NaN      NaN              NaN              NaN   \n",
       "21                       NaN      NaN              NaN              NaN   \n",
       "22                       NaN      NaN              NaN              NaN   \n",
       "23                       NaN      NaN              NaN              NaN   \n",
       "24                       NaN      NaN              NaN              NaN   \n",
       "25                       NaN      NaN              NaN              NaN   \n",
       "\n",
       "    albumin urine  alkaline phosphate  anion gap  asparate aminotransferase  \\\n",
       "0             NaN                73.0  20.666666                       69.0   \n",
       "1             NaN                 NaN        NaN                        NaN   \n",
       "2             NaN                 NaN        NaN                        NaN   \n",
       "3             NaN                 NaN        NaN                        NaN   \n",
       "4             NaN                 NaN        NaN                        NaN   \n",
       "5             NaN                 NaN        NaN                        NaN   \n",
       "6             NaN                 NaN        NaN                        NaN   \n",
       "7             NaN                 NaN  19.000000                        NaN   \n",
       "8             NaN                 NaN        NaN                        NaN   \n",
       "9             NaN                 NaN        NaN                        NaN   \n",
       "10            NaN                 NaN        NaN                        NaN   \n",
       "11            NaN                 NaN        NaN                        NaN   \n",
       "12            NaN                 NaN        NaN                        NaN   \n",
       "13            NaN                 NaN        NaN                        NaN   \n",
       "14            NaN                 NaN        NaN                        NaN   \n",
       "15            NaN                 NaN        NaN                        NaN   \n",
       "16            NaN                 NaN        NaN                        NaN   \n",
       "17            NaN                 NaN  15.000000                        NaN   \n",
       "18            NaN                 NaN        NaN                        NaN   \n",
       "19            NaN                 NaN        NaN                        NaN   \n",
       "20            NaN                 NaN        NaN                        NaN   \n",
       "21            NaN                 NaN        NaN                        NaN   \n",
       "22            NaN                 NaN        NaN                        NaN   \n",
       "23            NaN                 NaN        NaN                        NaN   \n",
       "24            NaN                 NaN        NaN                        NaN   \n",
       "25            NaN                 NaN        NaN                        NaN   \n",
       "\n",
       "    basophils  bicarbonate  bilirubin  blood urea nitrogen  calcium  \\\n",
       "0         NaN    16.333334        0.8                 44.2     6.92   \n",
       "1         NaN          NaN        NaN                  NaN      NaN   \n",
       "2         NaN          NaN        NaN                  NaN      NaN   \n",
       "3         NaN          NaN        NaN                  NaN      NaN   \n",
       "4         NaN          NaN        NaN                  NaN      NaN   \n",
       "5         NaN          NaN        NaN                  NaN      NaN   \n",
       "6         NaN    15.000000        NaN                  NaN      NaN   \n",
       "7         NaN    13.000000        NaN                 42.0     6.70   \n",
       "8         NaN          NaN        NaN                  NaN      NaN   \n",
       "9         NaN          NaN        NaN                  NaN      NaN   \n",
       "10        NaN          NaN        NaN                  NaN      NaN   \n",
       "11        NaN          NaN        NaN                  NaN      NaN   \n",
       "12        NaN          NaN        NaN                  NaN      NaN   \n",
       "13        NaN          NaN        NaN                  NaN      NaN   \n",
       "14        NaN          NaN        NaN                  NaN      NaN   \n",
       "15        NaN          NaN        NaN                  NaN      NaN   \n",
       "16        NaN          NaN        NaN                  NaN      NaN   \n",
       "17        NaN    17.000000        NaN                  NaN      NaN   \n",
       "18        NaN          NaN        NaN                  NaN      NaN   \n",
       "19        NaN          NaN        NaN                  NaN      NaN   \n",
       "20        NaN          NaN        NaN                  NaN      NaN   \n",
       "21        NaN          NaN        NaN                  NaN      NaN   \n",
       "22        NaN          NaN        NaN                  NaN      NaN   \n",
       "23        NaN          NaN        NaN                  NaN      NaN   \n",
       "24        NaN          NaN        NaN                  NaN      NaN   \n",
       "25        NaN          NaN        NaN                  NaN      NaN   \n",
       "\n",
       "    calcium ionized  calcium urine  \n",
       "0          0.963333            NaN  \n",
       "1               NaN            NaN  \n",
       "2          1.060000            NaN  \n",
       "3               NaN            NaN  \n",
       "4               NaN            NaN  \n",
       "5               NaN            NaN  \n",
       "6          1.030000            NaN  \n",
       "7               NaN            NaN  \n",
       "8               NaN            NaN  \n",
       "9               NaN            NaN  \n",
       "10              NaN            NaN  \n",
       "11              NaN            NaN  \n",
       "12              NaN            NaN  \n",
       "13         1.110000            NaN  \n",
       "14              NaN            NaN  \n",
       "15              NaN            NaN  \n",
       "16              NaN            NaN  \n",
       "17              NaN            NaN  \n",
       "18              NaN            NaN  \n",
       "19              NaN            NaN  \n",
       "20         1.130000            NaN  \n",
       "21              NaN            NaN  \n",
       "22              NaN            NaN  \n",
       "23              NaN            NaN  \n",
       "24              NaN            NaN  \n",
       "25              NaN            NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.iloc[:26, :20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vitals = TidySequentialDataCSVLoader(\n",
    "    x_csv_path=train_x,\n",
    "    y_csv_path=train_y,\n",
    "    x_col_names=feature_cols,\n",
    "    idx_col_names=id_cols,\n",
    "    y_col_name=\"mort_hosp\",\n",
    "    y_label_type='per_sequence'\n",
    ")\n",
    "\n",
    "valid_vitals = TidySequentialDataCSVLoader(\n",
    "    x_csv_path=valid_x,\n",
    "    y_csv_path=valid_y,\n",
    "    x_col_names=feature_cols,\n",
    "    idx_col_names=id_cols,\n",
    "    y_col_name=\"mort_hosp\",\n",
    "    y_label_type='per_sequence'\n",
    ")\n",
    "\n",
    "test_vitals = TidySequentialDataCSVLoader(\n",
    "    x_csv_path=test_x,\n",
    "    y_csv_path=test_y,\n",
    "    x_col_names=feature_cols,\n",
    "    idx_col_names=id_cols,\n",
    "    y_col_name=\"mort_hosp\",\n",
    "    y_label_type='per_sequence'\n",
    ")\n",
    "\n",
    "# num_true_feats = int(F/3)\n",
    "train_x_NTD, y_train = train_vitals.get_batch_data(batch_id=0)\n",
    "valid_x_NTD, y_valid = valid_vitals.get_batch_data(batch_id=0)\n",
    "test_x_NTD, y_test = test_vitals.get_batch_data(batch_id=0)\n",
    "\n",
    "N_tr = len(train_x_NTD)\n",
    "N_va = len(valid_x_NTD)\n",
    "N_te = len(test_x_NTD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fraction positive labels in train set : 0.0965\n",
      "fraction positive labels in valid set : 0.0938\n",
      "fraction positive labels in test set : 0.0993\n"
     ]
    }
   ],
   "source": [
    "for split, y in [('train', y_train),\n",
    "                ('valid', y_valid),\n",
    "                ('test', y_test)]:\n",
    "    print('fraction positive labels in %s set : %.4f'%(split, y.sum()/len(y)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "CREATING TRAIN/VALID/TEST SPLITS FOR 1.200 PERCENT OF SEQUENCES LABELLED\n",
      "---------------------------------------------------------------------------\n",
      "Excluded inds train: 2995, 957, 4074 ... 11398, 9140, 18547\n",
      "Excluded inds valid: 671, 846, 2062 ... 1448, 3199, 174\n",
      "Excluded inds test: 1383, 2603, 5628 ... 3199, 174, 434\n",
      "Saving data to /cluster/tufts/hugheslab/prath01/datasets/mimic3_ssl/percentage_labelled_sequnces=1.2\n",
      "Done saving train..\n",
      "Done saving valid..\n",
      "Done saving test..\n",
      "---------------------------------------------------------------------------\n",
      "fraction positive labels in train set with 1.200 percent of sequences labelled : 0.0933\n",
      "fraction positive labels in valid set with 1.200 percent of sequences labelled : 0.0351\n",
      "fraction positive labels in test set with 1.200 percent of sequences labelled : 0.0423\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "state_id = 41\n",
    "data_save_dir = '/cluster/tufts/hugheslab/prath01/datasets/mimic3_ssl/'\n",
    "\n",
    "for ii, perc_labelled in enumerate([1.2]):#3.7, 11.1, 33.3, 100\n",
    "    curr_save_dir = os.path.join(data_save_dir, 'percentage_labelled_sequnces=%s'%perc_labelled)\n",
    "    \n",
    "    print('---------------------------------------------------------------------------')\n",
    "    print('CREATING TRAIN/VALID/TEST SPLITS FOR %.3f PERCENT OF SEQUENCES LABELLED'%perc_labelled)\n",
    "    print('---------------------------------------------------------------------------')\n",
    "    y_train_ss = y_train.copy()\n",
    "    rnd_state = np.random.RandomState(state_id)\n",
    "    n_unlabelled_tr = int((1-(perc_labelled)/100)*N_tr)\n",
    "    unlabelled_inds_tr = rnd_state.permutation(N_tr)[:n_unlabelled_tr]\n",
    "    y_train_ss = y_train_ss.astype(np.float32)\n",
    "    y_train_ss[unlabelled_inds_tr] = np.nan  \n",
    "    if perc_labelled!=100:\n",
    "        print('Excluded inds train: %d, %d, %d ... %d, %d, %d'%(unlabelled_inds_tr[0],\n",
    "                                                              unlabelled_inds_tr[1],\n",
    "                                                              unlabelled_inds_tr[2],\n",
    "                                                              unlabelled_inds_tr[-3],\n",
    "                                                              unlabelled_inds_tr[-2],\n",
    "                                                              unlabelled_inds_tr[-1]))\n",
    "    \n",
    "    y_valid_ss = y_valid.copy()\n",
    "    rnd_state = np.random.RandomState(state_id)\n",
    "    n_unlabelled_va = int((1-(perc_labelled)/100)*N_va)\n",
    "    unlabelled_inds_va = rnd_state.permutation(N_va)[:n_unlabelled_va]\n",
    "    y_valid_ss = y_valid_ss.astype(np.float32)\n",
    "    y_valid_ss[unlabelled_inds_va] = np.nan \n",
    "    if perc_labelled!=100:\n",
    "        print('Excluded inds valid: %d, %d, %d ... %d, %d, %d'%(unlabelled_inds_va[0],\n",
    "                                                          unlabelled_inds_va[1],\n",
    "                                                          unlabelled_inds_va[2],\n",
    "                                                          unlabelled_inds_va[-3],\n",
    "                                                          unlabelled_inds_va[-2],\n",
    "                                                          unlabelled_inds_va[-1]))\n",
    "\n",
    "    y_test_ss = y_test.copy()\n",
    "    rnd_state = np.random.RandomState(state_id)\n",
    "    n_unlabelled_te = int((1-(perc_labelled)/100)*N_te)\n",
    "    unlabelled_inds_te = rnd_state.permutation(N_te)[:n_unlabelled_te]\n",
    "    y_test_ss = y_test_ss.astype(np.float32)\n",
    "    y_test_ss[unlabelled_inds_te] = np.nan\n",
    "    if perc_labelled!=100:\n",
    "        print('Excluded inds test: %d, %d, %d ... %d, %d, %d'%(unlabelled_inds_te[0],\n",
    "                                                          unlabelled_inds_te[1],\n",
    "                                                          unlabelled_inds_te[2],\n",
    "                                                          unlabelled_inds_te[-3],\n",
    "                                                          unlabelled_inds_te[-2],\n",
    "                                                          unlabelled_inds_te[-1]))\n",
    "    \n",
    "    # Check whether the specified path exists or not\n",
    "    isExist = os.path.exists(curr_save_dir)\n",
    "\n",
    "    if not isExist:\n",
    "        # Create a new directory because it does not exist \n",
    "        os.makedirs(curr_save_dir)\n",
    "        \n",
    "    # save the data to the respective folder\n",
    "    print('Saving data to %s'%curr_save_dir)\n",
    "    np.save(os.path.join(curr_save_dir, 'X_train.npy'), train_x_NTD)\n",
    "    np.save(os.path.join(curr_save_dir, 'y_train.npy'), y_train_ss)\n",
    "    print('Done saving train..')\n",
    "    np.save(os.path.join(curr_save_dir, 'X_valid.npy'), valid_x_NTD)\n",
    "    np.save(os.path.join(curr_save_dir, 'y_valid.npy'), y_valid_ss)\n",
    "    print('Done saving valid..')\n",
    "    np.save(os.path.join(curr_save_dir, 'X_test.npy'), test_x_NTD)\n",
    "    np.save(os.path.join(curr_save_dir, 'y_test.npy'), y_test_ss)\n",
    "    print('Done saving test..')\n",
    "    \n",
    "    \n",
    "    print('---------------------------------------------------------------------------')\n",
    "    for split, y in [('train', y_train_ss),\n",
    "                    ('valid', y_valid_ss),\n",
    "                    ('test', y_test_ss)]:\n",
    "        frac_pos_labels = np.nansum(y)/(~np.isnan(y)).sum()\n",
    "        print('fraction positive labels in %s set with %.3f percent of sequences labelled : %.4f'%(split,\n",
    "                                                                                                   perc_labelled,\n",
    "                                                                                                   frac_pos_labels))\n",
    "    print('---------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid_NTD_loaded = np.load('X_valid.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 50.84156,  45.     ,   4.9    , ...,       nan,  10.4    ,\n",
       "               nan],\n",
       "        [ 50.84156,       nan,       nan, ...,       nan,       nan,\n",
       "               nan],\n",
       "        [ 50.84156,       nan,       nan, ...,       nan,       nan,\n",
       "               nan],\n",
       "        ...,\n",
       "        [ 50.84156,       nan,       nan, ...,       nan,       nan,\n",
       "               nan],\n",
       "        [ 50.84156,       nan,       nan, ...,       nan,       nan,\n",
       "               nan],\n",
       "        [ 50.84156,       nan,       nan, ...,       nan,       nan,\n",
       "               nan]],\n",
       "\n",
       "       [[300.00308,       nan,       nan, ...,       nan,       nan,\n",
       "               nan],\n",
       "        [300.00308,       nan,       nan, ...,       nan,       nan,\n",
       "               nan],\n",
       "        [300.00308,       nan,       nan, ...,       nan,       nan,\n",
       "               nan],\n",
       "        ...,\n",
       "        [300.00308,       nan,       nan, ...,       nan,       nan,\n",
       "               nan],\n",
       "        [300.00308,       nan,       nan, ...,       nan,       nan,\n",
       "               nan],\n",
       "        [300.00308,       nan,       nan, ...,       nan,       nan,\n",
       "               nan]],\n",
       "\n",
       "       [[ 69.44273,       nan,       nan, ...,       nan,       nan,\n",
       "               nan],\n",
       "        [ 69.44273,       nan,       nan, ...,       nan,       nan,\n",
       "               nan],\n",
       "        [ 69.44273,       nan,       nan, ...,       nan,  11.5    ,\n",
       "               nan],\n",
       "        ...,\n",
       "        [ 69.44273,       nan,       nan, ...,       nan,       nan,\n",
       "               nan],\n",
       "        [ 69.44273,       nan,       nan, ...,       nan,       nan,\n",
       "               nan],\n",
       "        [ 69.44273,       nan,       nan, ...,       nan,       nan,\n",
       "               nan]]], dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_valid_NTD_loaded[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 50.84156,  45.     ,   4.9    , ...,       nan,  10.4    ,\n",
       "               nan],\n",
       "        [ 50.84156,       nan,       nan, ...,       nan,       nan,\n",
       "               nan],\n",
       "        [ 50.84156,       nan,       nan, ...,       nan,       nan,\n",
       "               nan],\n",
       "        ...,\n",
       "        [ 50.84156,       nan,       nan, ...,       nan,       nan,\n",
       "               nan],\n",
       "        [ 50.84156,       nan,       nan, ...,       nan,       nan,\n",
       "               nan],\n",
       "        [ 50.84156,       nan,       nan, ...,       nan,       nan,\n",
       "               nan]],\n",
       "\n",
       "       [[300.00308,       nan,       nan, ...,       nan,       nan,\n",
       "               nan],\n",
       "        [300.00308,       nan,       nan, ...,       nan,       nan,\n",
       "               nan],\n",
       "        [300.00308,       nan,       nan, ...,       nan,       nan,\n",
       "               nan],\n",
       "        ...,\n",
       "        [300.00308,       nan,       nan, ...,       nan,       nan,\n",
       "               nan],\n",
       "        [300.00308,       nan,       nan, ...,       nan,       nan,\n",
       "               nan],\n",
       "        [300.00308,       nan,       nan, ...,       nan,       nan,\n",
       "               nan]],\n",
       "\n",
       "       [[ 69.44273,       nan,       nan, ...,       nan,       nan,\n",
       "               nan],\n",
       "        [ 69.44273,       nan,       nan, ...,       nan,       nan,\n",
       "               nan],\n",
       "        [ 69.44273,       nan,       nan, ...,       nan,  11.5    ,\n",
       "               nan],\n",
       "        ...,\n",
       "        [ 69.44273,       nan,       nan, ...,       nan,       nan,\n",
       "               nan],\n",
       "        [ 69.44273,       nan,       nan, ...,       nan,       nan,\n",
       "               nan],\n",
       "        [ 69.44273,       nan,       nan, ...,       nan,       nan,\n",
       "               nan]]], dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_x_NTD[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the MIMIC collapsed features data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from featurize_single_time_series import collapse_std, collapse_elapsed_time_since_last_measured, collapse_count, collapse_slope, collapse_median, collapse_min, collapse_max, collapse_value_last_measured, make_summary_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collapse features\n",
    "def featurize_ts(\n",
    "        time_arr_by_var,\n",
    "        val_arr_by_var,\n",
    "        n_features,\n",
    "        percentile_slices_to_featurize=[(0., 100.)],\n",
    "        summary_ops=['count', 'mean', 'std', 'slope'],\n",
    "        ):\n",
    "    ''' Featurize provided multivariate irregular time series into flat vector\n",
    "    Args\n",
    "    ----\n",
    "    time_arr_by_var : dict of 1D NumPy arrays\n",
    "    val_arr_by_var : dict of 1D NumPy arrays\n",
    "    start_numerictime : float\n",
    "        Indicates numerical time value at which current window *starts*\n",
    "    stop_numerictime : float\n",
    "        Indicates numerical time that current window *stops*\n",
    "    Returns\n",
    "    -------\n",
    "    feat_vec_1F : 2D NumPy array, shape (1, F)\n",
    "        One entry for each combination of {variable, summary op, subwindow slice}\n",
    "    '''\n",
    "    \n",
    "    start_numerictime = 0\n",
    "    stop_numerictime = 24\n",
    "    time_range = stop_numerictime - start_numerictime\n",
    "\n",
    "    F = len(percentile_slices_to_featurize) * n_features * len (summary_ops)\n",
    "    feat_vec_1F = np.zeros((1, F))\n",
    "    ff = 0\n",
    "\n",
    "    SUMMARY_OPERATIONS = make_summary_ops()\n",
    "\n",
    "    for rp_ind, (low, high) in enumerate(percentile_slices_to_featurize):\n",
    "        cur_window_start_time = start_numerictime + float(low) / 100 * time_range\n",
    "        cur_window_stop_time = start_numerictime + float(high) / 100 * time_range\n",
    "\n",
    "        for var_id in range(n_features):\n",
    "            cur_feat_arr = val_arr_by_var[:, var_id].astype('float')\n",
    "            cur_numerictime_arr = time_arr_by_var\n",
    "\n",
    "            # Keep only the entries whose times occur within current window\n",
    "            start = np.searchsorted(\n",
    "                cur_numerictime_arr, cur_window_start_time, side='left')\n",
    "            stop = np.searchsorted(\n",
    "                cur_numerictime_arr, cur_window_stop_time, side='right')\n",
    "            cur_numerictime_arr = cur_numerictime_arr[start:stop]\n",
    "            cur_feat_arr = cur_feat_arr[start:stop]\n",
    "            cur_isfinite_arr = np.isfinite(cur_feat_arr)\n",
    "            \n",
    "            for op_ind, op in enumerate(summary_ops):\n",
    "                summary_func, empty_val = SUMMARY_OPERATIONS[op]\n",
    "                if cur_feat_arr.size < 1 or cur_isfinite_arr.sum() < 1:\n",
    "                    feat_vec_1F[0,ff] = empty_val\n",
    "                else:\n",
    "                    feat_vec_1F[0,ff] = summary_func(\n",
    "                        cur_feat_arr, cur_numerictime_arr, cur_isfinite_arr,\n",
    "                        cur_window_start_time, cur_window_stop_time)\n",
    "#                 feat_names.append(\"feature_%s_%s_%.0f-%.0f\" % (var_id, op, float(low), float(high)))\n",
    "                ff += 1\n",
    "    return feat_vec_1F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collapsing train feaures\n",
      "Done with 0 sequences..\n",
      "Done with 500 sequences..\n",
      "Done with 1000 sequences..\n",
      "Done with 1500 sequences..\n",
      "Done with 2000 sequences..\n",
      "Done with 2500 sequences..\n",
      "Done with 3000 sequences..\n",
      "Done with 3500 sequences..\n",
      "Done with 4000 sequences..\n",
      "Done with 4500 sequences..\n",
      "Done with 5000 sequences..\n",
      "Done with 5500 sequences..\n",
      "Done with 6000 sequences..\n",
      "Done with 6500 sequences..\n",
      "Done with 7000 sequences..\n",
      "Done with 7500 sequences..\n",
      "Done with 8000 sequences..\n",
      "Done with 8500 sequences..\n",
      "Done with 9000 sequences..\n",
      "Done with 9500 sequences..\n",
      "Done with 10000 sequences..\n",
      "Done with 10500 sequences..\n",
      "Done with 11000 sequences..\n",
      "Done with 11500 sequences..\n",
      "Done with 12000 sequences..\n",
      "Done with 12500 sequences..\n",
      "Done with 13000 sequences..\n",
      "Done with 13500 sequences..\n",
      "Done with 14000 sequences..\n",
      "Done with 14500 sequences..\n",
      "Done with 15000 sequences..\n",
      "Done with 15500 sequences..\n",
      "Done with 16000 sequences..\n",
      "Done with 16500 sequences..\n",
      "Done with 17000 sequences..\n",
      "Done with 17500 sequences..\n",
      "Done with 18000 sequences..\n",
      "Done with 18500 sequences..\n",
      "Collapsing valid feaures\n",
      "Done with 0 sequences..\n",
      "Done with 500 sequences..\n",
      "Done with 1000 sequences..\n",
      "Done with 1500 sequences..\n",
      "Done with 2000 sequences..\n",
      "Done with 2500 sequences..\n",
      "Done with 3000 sequences..\n",
      "Done with 3500 sequences..\n",
      "Done with 4000 sequences..\n",
      "Done with 4500 sequences..\n",
      "Collapsing test feaures\n",
      "Done with 0 sequences..\n",
      "Done with 500 sequences..\n",
      "Done with 1000 sequences..\n",
      "Done with 1500 sequences..\n",
      "Done with 2000 sequences..\n",
      "Done with 2500 sequences..\n",
      "Done with 3000 sequences..\n",
      "Done with 3500 sequences..\n",
      "Done with 4000 sequences..\n",
      "Done with 4500 sequences..\n",
      "Done with 5000 sequences..\n",
      "Done with 5500 sequences..\n"
     ]
    }
   ],
   "source": [
    "N_tr = len(train_x_NTD)\n",
    "N_va = len(valid_x_NTD)\n",
    "N_te = len(test_x_NTD)\n",
    "percentile_slices_to_featurize = [(0., 100.), (90, 100)]\n",
    "summary_ops = [\"std\", \"time_since_measured\", \"count\", \"slope\", \"median\", \"min\", \"max\", \"last_value_measured\"]\n",
    "n_features = train_x_NTD.shape[-1]\n",
    "F = len(percentile_slices_to_featurize) * n_features * len (summary_ops)\n",
    "\n",
    "\n",
    "train_x_collapsed_NF = np.zeros((N_tr, F))\n",
    "valid_x_collapsed_NF = np.zeros((N_va, F))\n",
    "test_x_collapsed_NF = np.zeros((N_te, F))\n",
    "\n",
    "print('Collapsing train feaures')\n",
    "for nn in range(N_tr):\n",
    "    if (nn%500)==0:\n",
    "        print('Done with %s sequences..'%nn)\n",
    "    train_x_collapsed_NF[nn, :] = featurize_ts(np.arange(0, 25).astype(float),\n",
    "                                               train_x_NTD[nn],\n",
    "                                               n_features,\n",
    "                                               percentile_slices_to_featurize=[(0., 100.), (90, 100)],\n",
    "                                               summary_ops=[\"std\", \"time_since_measured\", \n",
    "                                                            \"count\", \"slope\", \"median\", \n",
    "                                                            \"min\", \"max\", \"last_value_measured\"])\n",
    "print('Collapsing valid feaures')\n",
    "for nn in range(N_va):\n",
    "    if (nn%500)==0:\n",
    "        print('Done with %s sequences..'%nn)\n",
    "    valid_x_collapsed_NF[nn, :] = featurize_ts(np.arange(0, 25).astype(float),\n",
    "                                               valid_x_NTD[nn],\n",
    "                                               n_features,\n",
    "                                               percentile_slices_to_featurize=[(0., 100.), (90, 100)],\n",
    "                                               summary_ops=[\"std\", \"time_since_measured\", \n",
    "                                                            \"count\", \"slope\", \"median\", \n",
    "                                                            \"min\", \"max\", \"last_value_measured\"])\n",
    "\n",
    "print('Collapsing test feaures')\n",
    "for nn in range(N_te):\n",
    "    if (nn%500)==0:\n",
    "        print('Done with %s sequences..'%nn)\n",
    "    test_x_collapsed_NF[nn, :] = featurize_ts(np.arange(0, 25).astype(float),\n",
    "                                               test_x_NTD[nn],\n",
    "                                               n_features,\n",
    "                                               percentile_slices_to_featurize=[(0., 100.), (90, 100)],\n",
    "                                               summary_ops=[\"std\", \"time_since_measured\", \n",
    "                                                            \"count\", \"slope\", \"median\", \n",
    "                                                            \"min\", \"max\", \"last_value_measured\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "CREATING TRAIN/VALID/TEST SPLITS FOR 1.200 PERCENT OF SEQUENCES LABELLED\n",
      "---------------------------------------------------------------------------\n",
      "Excluded inds train: 2995, 957, 4074 ... 11398, 9140, 18547\n",
      "Excluded inds valid: 671, 846, 2062 ... 1448, 3199, 174\n",
      "Excluded inds test: 1383, 2603, 5628 ... 3199, 174, 434\n",
      "Saving data to /cluster/tufts/hugheslab/prath01/datasets/mimic3_ssl/percentage_labelled_sequnces=1.2\n",
      "Done saving train..\n",
      "Done saving valid..\n",
      "Done saving test..\n"
     ]
    }
   ],
   "source": [
    "state_id = 41\n",
    "data_save_dir = '/cluster/tufts/hugheslab/prath01/datasets/mimic3_ssl/'\n",
    "\n",
    "for ii, perc_labelled in enumerate([1.2]):#3.7, 11.1, 33.3, 100\n",
    "    curr_save_dir = os.path.join(data_save_dir, 'percentage_labelled_sequnces=%s'%perc_labelled)\n",
    "    \n",
    "    print('---------------------------------------------------------------------------')\n",
    "    print('CREATING TRAIN/VALID/TEST SPLITS FOR %.3f PERCENT OF SEQUENCES LABELLED'%perc_labelled)\n",
    "    print('---------------------------------------------------------------------------')\n",
    "    y_train_ss = y_train.copy()\n",
    "    rnd_state = np.random.RandomState(state_id)\n",
    "    n_unlabelled_tr = int((1-(perc_labelled)/100)*N_tr)\n",
    "    unlabelled_inds_tr = rnd_state.permutation(N_tr)[:n_unlabelled_tr]\n",
    "    y_train_ss = y_train_ss.astype(np.float32)\n",
    "    y_train_ss[unlabelled_inds_tr] = np.nan  \n",
    "    if perc_labelled!=100:\n",
    "        print('Excluded inds train: %d, %d, %d ... %d, %d, %d'%(unlabelled_inds_tr[0],\n",
    "                                                              unlabelled_inds_tr[1],\n",
    "                                                              unlabelled_inds_tr[2],\n",
    "                                                              unlabelled_inds_tr[-3],\n",
    "                                                              unlabelled_inds_tr[-2],\n",
    "                                                              unlabelled_inds_tr[-1]))\n",
    "    \n",
    "    y_valid_ss = y_valid.copy()\n",
    "    rnd_state = np.random.RandomState(state_id)\n",
    "    n_unlabelled_va = int((1-(perc_labelled)/100)*N_va)\n",
    "    unlabelled_inds_va = rnd_state.permutation(N_va)[:n_unlabelled_va]\n",
    "    y_valid_ss = y_valid_ss.astype(np.float32)\n",
    "    y_valid_ss[unlabelled_inds_va] = np.nan \n",
    "    if perc_labelled!=100:\n",
    "        print('Excluded inds valid: %d, %d, %d ... %d, %d, %d'%(unlabelled_inds_va[0],\n",
    "                                                          unlabelled_inds_va[1],\n",
    "                                                          unlabelled_inds_va[2],\n",
    "                                                          unlabelled_inds_va[-3],\n",
    "                                                          unlabelled_inds_va[-2],\n",
    "                                                          unlabelled_inds_va[-1]))\n",
    "\n",
    "    y_test_ss = y_test.copy()\n",
    "    rnd_state = np.random.RandomState(state_id)\n",
    "    n_unlabelled_te = int((1-(perc_labelled)/100)*N_te)\n",
    "    unlabelled_inds_te = rnd_state.permutation(N_te)[:n_unlabelled_te]\n",
    "    y_test_ss = y_test_ss.astype(np.float32)\n",
    "    y_test_ss[unlabelled_inds_te] = np.nan\n",
    "    if perc_labelled!=100:\n",
    "        print('Excluded inds test: %d, %d, %d ... %d, %d, %d'%(unlabelled_inds_te[0],\n",
    "                                                          unlabelled_inds_te[1],\n",
    "                                                          unlabelled_inds_te[2],\n",
    "                                                          unlabelled_inds_te[-3],\n",
    "                                                          unlabelled_inds_te[-2],\n",
    "                                                          unlabelled_inds_te[-1]))\n",
    "    \n",
    "    # Check whether the specified path exists or not\n",
    "    isExist = os.path.exists(curr_save_dir)\n",
    "\n",
    "    if not isExist:\n",
    "        # Create a new directory because it does not exist \n",
    "        os.makedirs(curr_save_dir)\n",
    "        \n",
    "    # save the data to the respective folder\n",
    "    print('Saving data to %s'%curr_save_dir)\n",
    "    np.save(os.path.join(curr_save_dir, 'X_train_collapsed.npy'), train_x_collapsed_NF)\n",
    "    np.save(os.path.join(curr_save_dir, 'y_train_collapsed.npy'), y_train_ss)\n",
    "    print('Done saving train..')\n",
    "    np.save(os.path.join(curr_save_dir, 'X_valid_collapsed.npy'), valid_x_collapsed_NF)\n",
    "    np.save(os.path.join(curr_save_dir, 'y_valid_collapsed.npy'), y_valid_ss)\n",
    "    print('Done saving valid..')\n",
    "    np.save(os.path.join(curr_save_dir, 'X_test_collapsed.npy'), test_x_collapsed_NF)\n",
    "    np.save(os.path.join(curr_save_dir, 'y_test_collapsed.npy'), y_test_ss)\n",
    "    print('Done saving test..')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2333333333333334"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3.7/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
